{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f4760cf",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86677806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Load images\n",
    "image_folder = '/Users/alirazi/Downloads/Data-2/24_chromosomes_object'\n",
    "images = load_images_from_folder(image_folder)\n",
    "\n",
    "# Preprocess images (e.g., resize, normalize, enhance contrast)\n",
    "# Implement advanced preprocessing for separating overlapping chromosomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d227cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image, target_size=(128, 128)):\n",
    "    # Resize the image to the target size\n",
    "    image = cv2.resize(image, target_size)\n",
    "    \n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    image = image.astype('float32') / 255.0\n",
    "    \n",
    "    # Enhance contrast using histogram equalization\n",
    "    image = cv2.equalizeHist(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Example usage\n",
    "preprocessed_images = [preprocess_image(image) for image in images]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6a3981",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386a0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET  # Assuming your annotations are in XML format\n",
    "\n",
    "def load_annotations(annotation_dir):\n",
    "    annotations = []\n",
    "\n",
    "    # Iterate through XML annotation files in the directory\n",
    "    for filename in os.listdir(annotation_dir):\n",
    "        if filename.endswith('.xml'):\n",
    "            annotation_path = os.path.join(annotation_dir, filename)\n",
    "            annotations.append(annotation_path)\n",
    "\n",
    "    return annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5151fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib \n",
    "path_train_eda = \"/Users/alirazi/Downloads/Data-2/24_chromosomes_object/JEPG\"\n",
    "data_train_eda_dir = pathlib.Path(path_train_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53292d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib \n",
    "path_test_eda = \"/Users/alirazi/Downloads/Data-2/24_chromosomes_object/JEPG\"\n",
    "data_test_eda_dir = pathlib.Path(path_test_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0054fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_eda_dir = os.path.join(data_test_eda_dir, 'test')\n",
    "y_test_eda_dir = os.path.join(data_test_eda_dir, 'testannot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d364e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dir = os.path.join(data_train_eda_dir, 'train')\n",
    "y_train_dir = os.path.join(data_train_eda_dir, 'trainannot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de548741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Define the directory paths\n",
    "path_train_eda = \"/Users/alirazi/Downloads/Data-2/24_chromosomes_object/JEPG\"\n",
    "path_test_eda = \"/Users/alirazi/Downloads/Data-2/24_chromosomes_object/JEPG\"\n",
    "\n",
    "# Convert paths to pathlib.Path objects\n",
    "data_train_eda_dir = pathlib.Path(path_train_eda)\n",
    "data_test_eda_dir = pathlib.Path(path_test_eda)\n",
    "\n",
    "# Define the subdirectories for training and testing data\n",
    "x_train_dir = data_train_eda_dir / 'train'\n",
    "y_train_dir = data_train_eda_dir / 'trainannot'\n",
    "x_test_dir = data_test_eda_dir / 'test'\n",
    "y_test_dir = data_test_eda_dir / 'testannot'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1cf2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def load_data(image_dir, annotation_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            annotation_path = os.path.join(annotation_dir, filename.replace('.jpg', '.xml'))\n",
    "\n",
    "            # Load the image\n",
    "            image = cv2.imread(image_path)\n",
    "            images.append(image)\n",
    "\n",
    "            # Load and parse the XML annotation\n",
    "            tree = ET.parse(annotation_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Assuming a binary classification problem where 'chromosome' is class 1, and 'non-chromosome' is class 0\n",
    "            label = 1 if any(obj.find('name').text == 'chromosome' for obj in root.findall('object')) else 0\n",
    "            labels.append(label)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Define paths to image and annotation directories\n",
    "image_dir = '/Users/alirazi/Downloads/Data-2/24_chromosomes_object/JEPG'\n",
    "annotation_dir = '/Users/alirazi/Downloads/Data-2/24_chromosomes_object/annotations'\n",
    "\n",
    "# Load data\n",
    "images, labels = load_data(image_dir, annotation_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4d4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9d18487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 13:21:54.134392: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'img_height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m----> 4\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[43mimg_height\u001b[49m, img_width, \u001b[38;5;241m3\u001b[39m)),\n\u001b[1;32m      5\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m      6\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[1;32m      7\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m2\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Two output classes: chromosome or non-chromosome\u001b[39;00m\n\u001b[1;32m      8\u001b[0m ])\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_height' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(2, activation='softmax')  # Two output classes: chromosome or non-chromosome\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8259624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for loading and preprocessing\n",
    "def load_and_preprocess_data(image_path, annotation_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)  # Adjust channels as per your images\n",
    "    image = tf.image.resize(image, (img_height, img_width))\n",
    "    image = tf.image.per_image_standardization(image)  # Normalize pixel values\n",
    "    \n",
    "    # Load and preprocess your annotations here\n",
    "    annotation = preprocess_annotations(annotation_path)\n",
    "\n",
    "    return image, annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef101243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths to image and annotation directories\n",
    "image_dir = '/Users/alirazi/Downloads/Data-2/24_chromosomes_object/JEPG'\n",
    "annotation_dir = '/Users/alirazi/Downloads/Data-2/24_chromosomes_object/annotations'\n",
    "\n",
    "# Function to extract ROIs from annotations\n",
    "def extract_rois_from_annotations(annotation_dir, image_dir):\n",
    "    rois = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(annotation_dir):\n",
    "        if filename.endswith('.xml'):\n",
    "            annotation_path = os.path.join(annotation_dir, filename)\n",
    "            image_filename = os.path.splitext(filename)[0] + '.jpg'\n",
    "            image_path = os.path.join(image_dir, image_filename)\n",
    "\n",
    "            tree = ET.parse(annotation_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            for object in root.findall('object'):\n",
    "                name = object.find('name').text\n",
    "                bndbox = object.find('bndbox')\n",
    "                xmin = int(bndbox.find('xmin').text)\n",
    "                ymin = int(bndbox.find('ymin').text)\n",
    "                xmax = int(bndbox.find('xmax').text)\n",
    "                ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "                # Load the image\n",
    "                img = cv2.imread(image_path)\n",
    "                roi = img[ymin:ymax, xmin:xmax]\n",
    "\n",
    "                rois.append(roi)\n",
    "                labels.append(1 if 'chromosome' in name else 0)  # Modify as needed\n",
    "\n",
    "    return rois, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ec175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ROIs and labels from annotations\n",
    "rois, labels = extract_rois_from_annotations(annotation_dir, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(rois, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3474c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Convert your data to NumPy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Now you have X_train, y_train for training and X_test, y_test for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ebec65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m patha0\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/alirazi/Downloads/Data-2/24_chromosomes_object/annotations/103064.xml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mpath0\u001b[49m)\n\u001b[1;32m      3\u001b[0m tree \u001b[38;5;241m=\u001b[39m ET\u001b[38;5;241m.\u001b[39mparse(patha0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path0' is not defined"
     ]
    }
   ],
   "source": [
    "patha0='/Users/alirazi/Downloads/Data-2/24_chromosomes_object/annotations/103064.xml'\n",
    "image = cv2.imread(path0)\n",
    "tree = ET.parse(patha0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f77da95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
